{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aba6b06c",
   "metadata": {},
   "source": [
    "# Buildathon Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ab8ebf",
   "metadata": {},
   "source": [
    "* Data\n",
    "    * Neuroprobe\n",
    "    * Splits\n",
    "* Processing\n",
    "    * Buffer Sampler\n",
    "    * Re-referencing Transform\n",
    "    * Patching Transform\n",
    "    * Masking\n",
    "* Training\n",
    "    * Pipeline and Baseline models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b398c09e",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "### Neuroprobe\n",
    "\n",
    "We added Neuroprobe to brainsets!!!\n",
    "\n",
    "Get the data with:\n",
    "`brainsets prepare neuroprobe_2025`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686a4af4",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '.venv (Python 3.10.19)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/utilisateur/Documents/torch_brain/.venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from temporaldata import Data\n",
    "import h5py\n",
    "\n",
    "path = \"Path to the data\"\n",
    "\n",
    "# Load the data from the h5py file\n",
    "with h5py.open(path) as f:\n",
    "    data = Data.from_hdf5(lazy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63ab9ae",
   "metadata": {},
   "source": [
    "### Splits\n",
    "\n",
    "There are a lot of tasks in the dataset, with each task having two splits of two folds.\n",
    "The existing splitting functionality wasn't enough so we added a better alternative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dff906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get your splits for task_1, fold_1\n",
    "data.splits.task_1.fold_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48084024",
   "metadata": {},
   "source": [
    "## Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f053f5e9",
   "metadata": {},
   "source": [
    "### Buffered Sampler\n",
    "\n",
    "Allows you to do preprocessing/filtering on the fly by avoiding edge effects for common filters.This means less storage use to test multiple processing parameters simulataneously.\n",
    "\n",
    "Planning to implement: \n",
    "* Multitaper Spectrograms\n",
    "* Fourier Transforms\n",
    "* Hipass, low-pass, notch...\n",
    "* Downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cc2eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_brain.data.buffer_sampler import BufferedSampler\n",
    "from torch_brain.data.sampler import RandomFixedWindowSampler\n",
    "\n",
    "\n",
    "fake_sampling_intervals = make_fake_sampling_intervals(num_records=1)\n",
    "for rec_id, domain in fake_sampling_intervals.items():\n",
    "    print(rec_id, domain.start, domain.end)\n",
    "\n",
    "sampler = RandomFixedWindowSampler(\n",
    "    sampling_intervals=fake_sampling_intervals,\n",
    "    window_length=1.0,\n",
    ")\n",
    "\n",
    "buffered_sampler = BufferedSampler(\n",
    "    base_sampler = sampler,\n",
    "    sampling_intervals=fake_sampling_intervals,\n",
    "    buffer_len =1.0,\n",
    ")\n",
    "\n",
    "sample = next(iter(buffered_sampler))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5815e580",
   "metadata": {},
   "source": [
    "### Re-referencing\n",
    " Bipolar, Laplacian, Common Average Reference, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae61cfb",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '.venv (Python 3.10.19)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/utilisateur/Documents/torch_brain/.venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from torch_brain.transforms.rereferencing import Rereferencing\n",
    "\n",
    "reref_transform = Rereferencing(type=\"laplace\")\n",
    "\n",
    "sample = reref_transform(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e635f0d",
   "metadata": {},
   "source": [
    "### Patching\n",
    "\n",
    "Multiple people implemented this on their side so it is important to have it as a part of the package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e592a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_brain.transforms.patching import RegularPatching\n",
    "\n",
    "patching_transform = RegularPatching(patch_duration=1.0, stride=0.5)\n",
    "\n",
    "sample = patching_transform(sample)\n",
    "print(sample.neural_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4c9aba",
   "metadata": {},
   "source": [
    "### Masking\n",
    "\n",
    "Implements three different types of masks: \n",
    "* Random Time Masking\n",
    "* Random Channel Masking\n",
    "* Random Block Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9fedf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_brain.transforms.masking import TimeMasking, ChannelMasking, BlockMasking\n",
    "\n",
    "mask_percentage = 0.35\n",
    "\n",
    "time_masking_transform = TimeMasking(mask_percentage=mask_percentage, window_duration=0.1)\n",
    "channel_masking_transform = ChannelMasking(mask_percentage=mask_percentage)\n",
    "block_masking_transform = BlockMasking(mask_percentage=mask_percentage, time_block_size=0.1, channel_block_size=4)\n",
    "\n",
    "sample = time_masking_transform(sample)\n",
    "# sample = channel_masking_transform(sample)\n",
    "# sample = block_masking_transform(sample)\n",
    "\n",
    "print(sample.neural_data.mask.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e6253c",
   "metadata": {},
   "source": [
    "## Training Pipeline and Baseline Models\n",
    "\n",
    "Training pipeline in `torch_brain/examples` and baseline models that consist of:\n",
    "* MLP\n",
    "* CNN\n",
    "\n",
    "Pipeline makes it easy to add new models and run neuroprobe benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b57646",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '.venv (Python 3.10.19)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/utilisateur/Documents/torch_brain/.venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# TODO: Add code snippet here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0d68c6",
   "metadata": {},
   "source": [
    "### Future direction\n",
    "\n",
    "Support exporting the results directly to the leaderboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee88e340",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
