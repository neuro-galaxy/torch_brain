{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76953fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['ROOT_DIR_BRAINTREEBANK'] = ''\n",
    "import h5py\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from temporaldata import Data\n",
    "import neuroprobe.config as neuroprobe_config\n",
    "from neuroprobe_utils.eval_utils import preprocess_data\n",
    "\n",
    "\n",
    "PROCESSED_DATA_PATH = '<ENTER PATH>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c943a4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "stft_parameters = {\n",
    "    \"nperseg\": 512,\n",
    "    \"poverlap\": 0.75,\n",
    "    \"window\": \"hann\",\n",
    "    \"max_frequency\": 150,\n",
    "    \"min_frequency\": 0\n",
    "}\n",
    "\n",
    "def _n_timebins_(n_samples: int, nperseg: int, poverlap: float, center: bool = True) -> int:\n",
    "    hop_length = int(nperseg * (1 - poverlap))\n",
    "    if center:\n",
    "        n_samples_eff = n_samples + 2 * (nperseg // 2)\n",
    "    else:\n",
    "        n_samples_eff = n_samples\n",
    "\n",
    "    n_timebins = np.floor((n_samples_eff - nperseg) / hop_length) + 1\n",
    "    return int(n_timebins)\n",
    "\n",
    "\n",
    "def _n_freqs_(sampling_rate: float, nperseg: int, fmin: float, fmax: float) -> int:\n",
    "    freqs = np.fft.rfftfreq(nperseg, d=1.0 / sampling_rate)\n",
    "    mask = (freqs >= fmin) & (freqs <= fmax)\n",
    "    return int(mask.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91087449",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "def run_neuroprobe_baseline(model_name, preprocess_type, preprocess_parameters):\n",
    "    iterations = list(product(\n",
    "        neuroprobe_config.NEUROPROBE_TASKS,\n",
    "        neuroprobe_config.NEUROPROBE_LITE_SUBJECT_TRIALS,\n",
    "        range(neuroprobe_config.NEUROPROBE_LITE_N_FOLDS)\n",
    "    ))\n",
    "    iterations = [\n",
    "        (eval_name, subject_id, trial_id, fold_idx)\n",
    "        for eval_name, (subject_id, trial_id), fold_idx in iterations\n",
    "    ]\n",
    "\n",
    "    results = []\n",
    "    pbar = tqdm.tqdm(iterations, desc=f\"\", leave=True)\n",
    "    for eval_name, subject_id, trial_id, fold_idx in pbar:\n",
    "        pbar.set_description(f\"Running {eval_name} (sub {subject_id}, trial {trial_id}, fold {fold_idx})\")\n",
    "        with h5py.File(os.path.join(PROCESSED_DATA_PATH, f'sub_{subject_id}_trial{trial_id:03d}.h5'), 'r') as f:\n",
    "            data = Data.from_hdf5(f)\n",
    "            train_split = getattr(data, f'{eval_name}_fold{fold_idx}_train')\n",
    "            test_split = getattr(data, f'{eval_name}_fold{fold_idx}_test')\n",
    "\n",
    "            split_included_channels_train = getattr(data.channels, f'included_{eval_name}_fold{fold_idx}_train')\n",
    "            split_included_channels_test = getattr(data.channels, f'included_{eval_name}_fold{fold_idx}_test')\n",
    "\n",
    "            if 'stft' in preprocess_type:\n",
    "                n_raw_samples_train = int(np.unique(train_split.end - train_split.start)[0] * neuroprobe_config.SAMPLING_RATE)\n",
    "                n_timebins_train = _n_timebins_(n_raw_samples_train, preprocess_parameters[\"stft\"][\"nperseg\"], preprocess_parameters[\"stft\"][\"poverlap\"], True)\n",
    "                n_freqs_train = _n_freqs_(neuroprobe_config.SAMPLING_RATE, preprocess_parameters[\"stft\"][\"nperseg\"], preprocess_parameters[\"stft\"][\"min_frequency\"], preprocess_parameters[\"stft\"][\"max_frequency\"])\n",
    "                num_samples_train = n_timebins_train * n_freqs_train * sum(split_included_channels_train)\n",
    "                \n",
    "                n_raw_samples_test = int(np.unique(test_split.end - test_split.start)[0] * neuroprobe_config.SAMPLING_RATE)\n",
    "                n_timebins_test = _n_timebins_(n_raw_samples_test, preprocess_parameters[\"stft\"][\"nperseg\"], preprocess_parameters[\"stft\"][\"poverlap\"], True)\n",
    "                n_freqs_test = _n_freqs_(neuroprobe_config.SAMPLING_RATE, preprocess_parameters[\"stft\"][\"nperseg\"], preprocess_parameters[\"stft\"][\"min_frequency\"], preprocess_parameters[\"stft\"][\"max_frequency\"])\n",
    "                num_samples_test = n_timebins_test * n_freqs_test * sum(split_included_channels_test)\n",
    "            else:\n",
    "                num_samples_train = neuroprobe_config.SAMPLING_RATE * sum(split_included_channels_train)\n",
    "                num_samples_test = neuroprobe_config.SAMPLING_RATE * sum(split_included_channels_test)\n",
    "\n",
    "            train_electrode_labels = data.channels.name[split_included_channels_train].tolist()\n",
    "            X_train = np.zeros((len(train_split), num_samples_train), dtype=np.float32)\n",
    "            y_train = np.zeros(len(train_split), dtype=np.int32)\n",
    "            # TODO more efficient way to do this?\n",
    "            for i in range(len(train_split)):\n",
    "                data_train = data.slice(train_split.start[i], train_split.end[i])\n",
    "                X_train[i, :] = preprocess_data(\n",
    "                    data_train.seeg_data.data[:, split_included_channels_train].T,\n",
    "                    train_electrode_labels,\n",
    "                    preprocess_type,\n",
    "                    preprocess_parameters,\n",
    "                ).flatten()\n",
    "                y_train[i] = train_split.label[i]\n",
    "\n",
    "            test_electrode_labels = data.channels.name[split_included_channels_test].tolist()\n",
    "            X_test = np.zeros((len(test_split), num_samples_test), dtype=np.float32)\n",
    "            y_test = np.zeros(len(test_split), dtype=np.int32)\n",
    "            for i in range(len(test_split)):\n",
    "                data_test = data.slice(test_split.start[i], test_split.end[i])\n",
    "                X_test[i, :] = preprocess_data(\n",
    "                    data_test.seeg_data.data[:, split_included_channels_test].T,\n",
    "                    test_electrode_labels,\n",
    "                    preprocess_type,\n",
    "                    preprocess_parameters,\n",
    "                ).flatten()\n",
    "                y_test[i] = test_split.label[i]\n",
    "            \n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "        clf = LogisticRegression(random_state=42, max_iter=1000, tol=1e-3)\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        train_score = clf.score(X_train, y_train)\n",
    "        test_score = clf.score(X_test, y_test)\n",
    "\n",
    "        try:\n",
    "            test_proba = clf.predict_proba(X_test)\n",
    "            # If y_test is multiclass, roc_auc_score needs multi_class='ovr'\n",
    "            if len(np.unique(y_test)) > 2:\n",
    "                test_auc = roc_auc_score(y_test, test_proba, multi_class='ovr')\n",
    "            else:\n",
    "                # For binary, use probability of class 1\n",
    "                test_auc = roc_auc_score(y_test, test_proba[:, 1])\n",
    "        except Exception as e:\n",
    "            print(f\"Could not compute ROC AUC: {e}\")\n",
    "            test_auc = float('nan')\n",
    "\n",
    "        results.append({\n",
    "            \"model_name\": model_name,\n",
    "            \"eval_name\": eval_name,\n",
    "            \"subject_id\": subject_id,\n",
    "            \"trial_id\": trial_id,\n",
    "            \"fold_idx\": fold_idx,\n",
    "            \"train_acc\": train_score,\n",
    "            \"test_acc\": test_score,\n",
    "            \"test_auc\": test_auc,\n",
    "        })\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    return results_df\n",
    "\n",
    "\n",
    "def print_model_results(results_df):\n",
    "    # Assumes results for single model\n",
    "    print('-' * 100)\n",
    "    grouped = results_df.groupby('eval_name', as_index=False)\n",
    "    task_means = grouped[['train_acc', 'test_acc', 'test_auc']].mean(numeric_only=True)\n",
    "    # auc_std = grouped['test_auc'].std().rename(columns={'test_auc': 'test_auc_std'})\n",
    "    auc_sem = grouped['test_auc'].sem().rename(columns={'test_auc': 'test_auc_sem'})\n",
    "    # task_means['test_auc_std'] = auc_std['test_auc_std']\n",
    "    task_means['test_auc_sem'] = auc_sem['test_auc_sem']\n",
    "    print(task_means)\n",
    "    print('-' * 100)\n",
    "    print(f\"Mean train accuracy: {task_means['train_acc'].mean():.4f}\")\n",
    "    print(f\"Mean test accuracy: {task_means['test_acc'].mean():.4f}\")\n",
    "    print(f\"Mean test AUC: {task_means['test_auc'].mean():.4f} ± {(task_means['test_auc_sem']**2).sum()**0.5 / len(task_means):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa454cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running face_num (sub 10, trial 1, fold 1): 100%|██████████| 360/360 [1:55:00<00:00, 19.17s/it]        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "           eval_name  train_acc  test_acc  test_auc  test_auc_sem\n",
      "0       delta_volume        1.0  0.690266  0.753039      0.013646\n",
      "1           face_num        1.0  0.499726  0.499039      0.005284\n",
      "2   frame_brightness        1.0  0.505580  0.507079      0.010881\n",
      "3        global_flow        1.0  0.524088  0.535152      0.007117\n",
      "4     gpt2_surprisal        1.0  0.559915  0.584387      0.006969\n",
      "5         local_flow        1.0  0.535423  0.544285      0.004338\n",
      "6              onset        1.0  0.727451  0.794724      0.015286\n",
      "7              pitch        1.0  0.526979  0.535886      0.004243\n",
      "8             speech        1.0  0.614515  0.655844      0.016394\n",
      "9             volume        1.0  0.569266  0.594880      0.011494\n",
      "10          word_gap        1.0  0.567905  0.595251      0.011042\n",
      "11     word_head_pos        1.0  0.549048  0.570358      0.006023\n",
      "12        word_index        1.0  0.682002  0.742012      0.012432\n",
      "13       word_length        1.0  0.572026  0.599440      0.009127\n",
      "14  word_part_speech        1.0  0.555511  0.576396      0.009168\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Mean train accuracy: 1.0000\n",
      "Mean test accuracy: 0.5786\n",
      "Mean test AUC: 0.6059 ± 0.0027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "preprocess_type = ''\n",
    "preprocess_parameters = {\"type\": preprocess_type}\n",
    "linear_raw_results = run_neuroprobe_baseline('Linear (raw)', preprocess_type, preprocess_parameters)\n",
    "print_model_results(linear_raw_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49445c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running face_num (sub 10, trial 1, fold 1): 100%|██████████| 360/360 [41:07<00:00,  6.85s/it]        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "           eval_name  train_acc  test_acc  test_auc  test_auc_sem\n",
      "0       delta_volume        1.0  0.662303  0.718109      0.017969\n",
      "1           face_num        1.0  0.518869  0.524925      0.006293\n",
      "2   frame_brightness        1.0  0.521796  0.533023      0.012438\n",
      "3        global_flow        1.0  0.567829  0.603799      0.013345\n",
      "4     gpt2_surprisal        1.0  0.548802  0.570385      0.012315\n",
      "5         local_flow        1.0  0.564284  0.592587      0.014368\n",
      "6              onset        1.0  0.776174  0.850897      0.018646\n",
      "7              pitch        1.0  0.547087  0.569822      0.008769\n",
      "8             speech        1.0  0.756011  0.825206      0.020790\n",
      "9             volume        1.0  0.663641  0.726024      0.027559\n",
      "10          word_gap        1.0  0.551678  0.579498      0.013650\n",
      "11     word_head_pos        1.0  0.544857  0.564990      0.008992\n",
      "12        word_index        1.0  0.616789  0.656744      0.020986\n",
      "13       word_length        1.0  0.550617  0.569021      0.012235\n",
      "14  word_part_speech        1.0  0.540994  0.558674      0.008220\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Mean train accuracy: 1.0000\n",
      "Mean test accuracy: 0.5954\n",
      "Mean test AUC: 0.6296 ± 0.0040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "preprocess_type = 'stft_abs'\n",
    "preprocess_parameters = {\"type\": preprocess_type, \"stft\": stft_parameters}\n",
    "stft_results = run_neuroprobe_baseline('Linear (STFT)', preprocess_type, preprocess_parameters)\n",
    "print_model_results(stft_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8bf9f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running face_num (sub 10, trial 1, fold 1): 100%|██████████| 360/360 [1:00:42<00:00, 10.12s/it]      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "           eval_name  train_acc  test_acc  test_auc  test_auc_sem\n",
      "0       delta_volume        1.0  0.700043  0.762268      0.018781\n",
      "1           face_num        1.0  0.519314  0.529991      0.010499\n",
      "2   frame_brightness        1.0  0.504834  0.520560      0.021550\n",
      "3        global_flow        1.0  0.583130  0.627021      0.011151\n",
      "4     gpt2_surprisal        1.0  0.579699  0.613087      0.012484\n",
      "5         local_flow        1.0  0.570840  0.607144      0.012947\n",
      "6              onset        1.0  0.820063  0.890582      0.016106\n",
      "7              pitch        1.0  0.553957  0.578374      0.012393\n",
      "8             speech        1.0  0.813079  0.882720      0.014732\n",
      "9             volume        1.0  0.644094  0.716555      0.023712\n",
      "10          word_gap        1.0  0.573870  0.611651      0.010623\n",
      "11     word_head_pos        1.0  0.571452  0.601639      0.009155\n",
      "12        word_index        1.0  0.683563  0.740119      0.020030\n",
      "13       word_length        1.0  0.585352  0.617582      0.010890\n",
      "14  word_part_speech        1.0  0.577560  0.605470      0.008901\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Mean train accuracy: 1.0000\n",
      "Mean test accuracy: 0.6187\n",
      "Mean test AUC: 0.6603 ± 0.0039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "preprocess_type = 'laplacian-stft_abs'\n",
    "preprocess_parameters = {\"type\": preprocess_type, \"stft\": stft_parameters}\n",
    "laplacian_stft_results = run_neuroprobe_baseline('Linear (Laplacian STFT)', preprocess_type, preprocess_parameters)\n",
    "print_model_results(laplacian_stft_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233bddd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>model_name</th>\n",
       "      <th>Linear (raw)</th>\n",
       "      <th>Linear (STFT)</th>\n",
       "      <th>Linear (Laplacian STFT)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ALL</th>\n",
       "      <td>0.605852</td>\n",
       "      <td>0.629580</td>\n",
       "      <td>0.660318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delta_volume</th>\n",
       "      <td>0.753039</td>\n",
       "      <td>0.718109</td>\n",
       "      <td>0.762268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>face_num</th>\n",
       "      <td>0.499039</td>\n",
       "      <td>0.524925</td>\n",
       "      <td>0.529991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frame_brightness</th>\n",
       "      <td>0.507079</td>\n",
       "      <td>0.533023</td>\n",
       "      <td>0.520560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>global_flow</th>\n",
       "      <td>0.535152</td>\n",
       "      <td>0.603799</td>\n",
       "      <td>0.627021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2_surprisal</th>\n",
       "      <td>0.584387</td>\n",
       "      <td>0.570385</td>\n",
       "      <td>0.613087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>local_flow</th>\n",
       "      <td>0.544285</td>\n",
       "      <td>0.592587</td>\n",
       "      <td>0.607144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>onset</th>\n",
       "      <td>0.794724</td>\n",
       "      <td>0.850897</td>\n",
       "      <td>0.890582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pitch</th>\n",
       "      <td>0.535886</td>\n",
       "      <td>0.569822</td>\n",
       "      <td>0.578374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>speech</th>\n",
       "      <td>0.655844</td>\n",
       "      <td>0.825206</td>\n",
       "      <td>0.882720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>volume</th>\n",
       "      <td>0.594880</td>\n",
       "      <td>0.726024</td>\n",
       "      <td>0.716555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_gap</th>\n",
       "      <td>0.595251</td>\n",
       "      <td>0.579498</td>\n",
       "      <td>0.611651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_head_pos</th>\n",
       "      <td>0.570358</td>\n",
       "      <td>0.564990</td>\n",
       "      <td>0.601639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_index</th>\n",
       "      <td>0.742012</td>\n",
       "      <td>0.656744</td>\n",
       "      <td>0.740119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_length</th>\n",
       "      <td>0.599440</td>\n",
       "      <td>0.569021</td>\n",
       "      <td>0.617582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_part_speech</th>\n",
       "      <td>0.576396</td>\n",
       "      <td>0.558674</td>\n",
       "      <td>0.605470</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "model_name        Linear (raw)  Linear (STFT)  Linear (Laplacian STFT)\n",
       "eval_name                                                             \n",
       "ALL                   0.605852       0.629580                 0.660318\n",
       "delta_volume          0.753039       0.718109                 0.762268\n",
       "face_num              0.499039       0.524925                 0.529991\n",
       "frame_brightness      0.507079       0.533023                 0.520560\n",
       "global_flow           0.535152       0.603799                 0.627021\n",
       "gpt2_surprisal        0.584387       0.570385                 0.613087\n",
       "local_flow            0.544285       0.592587                 0.607144\n",
       "onset                 0.794724       0.850897                 0.890582\n",
       "pitch                 0.535886       0.569822                 0.578374\n",
       "speech                0.655844       0.825206                 0.882720\n",
       "volume                0.594880       0.726024                 0.716555\n",
       "word_gap              0.595251       0.579498                 0.611651\n",
       "word_head_pos         0.570358       0.564990                 0.601639\n",
       "word_index            0.742012       0.656744                 0.740119\n",
       "word_length           0.599440       0.569021                 0.617582\n",
       "word_part_speech      0.576396       0.558674                 0.605470"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_results = pd.concat([laplacian_stft_results, stft_results, linear_raw_results], ignore_index=True)\n",
    "agg = (\n",
    "    combined_results\n",
    "    .groupby([\"model_name\", \"eval_name\"])\n",
    "    .agg(\n",
    "        train_acc_mean=(\"train_acc\", \"mean\"),\n",
    "        test_acc_mean=(\"test_acc\", \"mean\"),\n",
    "        test_auc_mean=(\"test_auc\", \"mean\"),\n",
    "        test_auc_sem=(\"test_auc\", lambda x: x.std(ddof=1) / np.sqrt(len(x)))\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "overall = (\n",
    "    agg\n",
    "    .groupby(\"model_name\")\n",
    "    .agg(\n",
    "        train_acc_mean=(\"train_acc_mean\", \"mean\"),\n",
    "        test_acc_mean=(\"test_acc_mean\", \"mean\"),\n",
    "        test_auc_mean=(\"test_auc_mean\", \"mean\"),\n",
    "        test_auc_sem=(\"test_auc_mean\", lambda x: x.std(ddof=1) / np.sqrt(len(x)))  # sem of means\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "overall[\"eval_name\"] = \"Total\"\n",
    "\n",
    "summary = pd.concat([agg, overall], ignore_index=True)\n",
    "auc_wide = summary.pivot(index=\"eval_name\", columns=\"model_name\", values=\"test_auc_mean\")\n",
    "auc_wide[['Linear (raw)', 'Linear (STFT)', 'Linear (Laplacian STFT)']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
