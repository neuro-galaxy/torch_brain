{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import h5py\n",
    "import logging\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from temporaldata import (\n",
    "    Data,\n",
    "    RegularTimeSeries,\n",
    "    IrregularTimeSeries,\n",
    "    Interval,\n",
    "    ArrayDict,\n",
    ")\n",
    "from brainsets.descriptions import (\n",
    "    BrainsetDescription,\n",
    "    SessionDescription,\n",
    "    SubjectDescription,\n",
    "    DeviceDescription,\n",
    ")\n",
    "from brainsets.taxonomy import Species, Sex, Cre_line, RecordingTech\n",
    "from brainsets.taxonomy.mice import BrainRegion\n",
    "from brainsets.taxonomy.allen import (\n",
    "    TEMPORAL_FREQ_5_map,\n",
    "    SPATIAL_FREQ_5_map,\n",
    "    ORIENTATION_12_CLASSES_map,\n",
    "    ORIENTATION_8_CLASSES_map,\n",
    "    PHASE_4_map,\n",
    ")\n",
    "from brainsets import serialize_fn_map\n",
    "\n",
    "from experanto.experiment import Experiment\n",
    "from experanto.configs import DEFAULT_MODALITY_CONFIG, DEFAULT_CONFIG\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "from datetime import datetime\n",
    "from experanto.dataloaders import get_multisession_dataloader\n",
    "from collections import Counter\n",
    "import json\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid_screen_intervals(valid_screen_times, to_add, start_add=0):\n",
    "    start_intervals = []\n",
    "    end_intervals = []\n",
    "    start = valid_screen_times[0] + start_add\n",
    "    for i in range(1, valid_screen_times.shape[0]):\n",
    "        prev = valid_screen_times[i-1]\n",
    "        if valid_screen_times[i] - valid_screen_times[i-1] > 0.33 * 1.5:\n",
    "            assert valid_screen_times[i] - valid_screen_times[i - 1] > to_add, 'wrong gap between two intervals'\n",
    "            start_intervals.append(start)\n",
    "            start = valid_screen_times[i] + start_add\n",
    "            end_intervals.append(valid_screen_times[i-1] + to_add)\n",
    "    assert len(start_intervals) == len(end_intervals), 'intervals length does not match'\n",
    "    start_intervals.append(start)\n",
    "    end_intervals.append(valid_screen_times[-1] + to_add)\n",
    "    # final_intervals = []\n",
    "    # for i in range(len(end_intervals)):\n",
    "    #     final_intervals.append(Interval(start_intervals[i], end_intervals[i]))\n",
    "    return Interval(start=np.asarray(start_intervals), end=np.asarray(end_intervals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_intervals_for_tier(experanto_base_folder, mouse_id_folder, calcium_traces, tier, DEFAULT_CONFIG):\n",
    "    DEFAULT_CONFIG['dataset']['modality_config']['screen']['valid_condition']['tier'] = tier\n",
    "    dl = get_multisession_dataloader(paths=[f'{experanto_base_folder}/{mouse_id_folder}'],\n",
    "                        configs=DEFAULT_CONFIG,\n",
    "                        shuffle_keys = False)\n",
    "    assert len(dl.loaders) == 1, 'too long dataloader'\n",
    "    kk = list(dl.loaders.keys())[0]\n",
    "    assert dl.loaders[kk].dataset._valid_screen_times.min() >= calcium_traces.domain.start, \"calcium traces start after the visual stimuli\"\n",
    "    to_add = DEFAULT_MODALITY_CONFIG['screen']['chunk_size'] / DEFAULT_MODALITY_CONFIG['screen']['sampling_rate']\n",
    "    assert calcium_traces.domain.end >= (dl.loaders[kk].dataset._valid_screen_times.max() + to_add), 'calcium traces end before visual stimuli'\n",
    "    # todo - this is hardcoded based on the interpolation period we had\n",
    "    if tier == 'train':\n",
    "        start_add = 0\n",
    "    else:\n",
    "        start_add = 5 / DEFAULT_MODALITY_CONFIG['screen']['sampling_rate']\n",
    "    return get_valid_screen_intervals(dl.loaders[kk].dataset._valid_screen_times, to_add, start_add)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fs(experiment, dev_name):\n",
    "        return experiment.modality_config[dev_name].get(\n",
    "            \"sampling_rate\", getattr(experiment.devices[dev_name], \"sampling_rate\", None)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_calcium_traces(experiment):\n",
    "    traces = experiment.devices['responses']._data\n",
    "    experiment.devices['responses'].normalize_init()\n",
    "    traces = experiment.devices['responses'].normalize_data(traces)\n",
    "    fs = experiment.modality_config[\"responses\"].get(\"sampling_rate\")\n",
    "    if fs is None:\n",
    "        # Fallback: check if the device object happens to store it\n",
    "        fs = getattr(\n",
    "            experiment.devices['responses'], \"sampling_rate\", 30.0\n",
    "        )  # Default to 30Hz (common for Ca) or 30000Hz (ephys)\n",
    "\n",
    "    start_time = experiment.devices['responses'].start_time\n",
    "    n_samples, _ = traces.shape\n",
    "    timestamps = start_time + np.arange(n_samples) / fs\n",
    "\n",
    "    # todo - make sure it should be time by neurons\n",
    "    calcium_traces = RegularTimeSeries(\n",
    "        df_over_f=np.array(traces),\n",
    "        sampling_rate=fs,\n",
    "        domain=\"auto\",\n",
    "        domain_start=timestamps[0],\n",
    "    )\n",
    "\n",
    "    return calcium_traces\n",
    "\n",
    "def extract_units(experanto_base_folder, mouse_id_folder):\n",
    "    units = np.load(f'{experanto_base_folder}/{mouse_id_folder}/responses/meta/unit_ids.npy')\n",
    "    cell_motor_coordinates = np.load(f'{experanto_base_folder}/{mouse_id_folder}/responses/meta/cell_motor_coordinates.npy')\n",
    "    units = ArrayDict(\n",
    "        id=units.astype(str),\n",
    "        imaging_plane_xy=cell_motor_coordinates[:, :2],\n",
    "        imaging_plane_height=cell_motor_coordinates[:, 2],\n",
    "    )\n",
    "    return units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_running_speed(experiment):\n",
    "    logging.info(\"Processing Treadmill...\")\n",
    "    running_speed = experiment.devices[\"treadmill\"]._data\n",
    "    experiment.devices[\"treadmill\"].normalize_init()\n",
    "    running_speed = experiment.devices[\"treadmill\"].normalize_data(running_speed)\n",
    "    tm_fs = get_fs(experiment, \"treadmill\")\n",
    "    # todo - what if tm_fs is None? \n",
    "    timestamps = experiment.devices[\"treadmill\"].start_time + np.arange(len(running_speed)) / tm_fs\n",
    "\n",
    "    nan_mask = np.isnan(running_speed).squeeze()\n",
    "    running_speed = running_speed[~nan_mask]\n",
    "    timestamps = timestamps[~nan_mask]\n",
    "\n",
    "    assert len(running_speed) == len(timestamps)\n",
    "\n",
    "    running_speed = IrregularTimeSeries(\n",
    "        timestamps=timestamps,\n",
    "        running_speed=running_speed.astype(np.float32).reshape(\n",
    "            -1, 1\n",
    "        ),  # continues values needs to be 2 dimensional\n",
    "        domain=\"auto\",\n",
    "    )\n",
    "    return running_speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pupil_info(experiment):\n",
    "    logging.info(\"Processing Eye Tracker...\")\n",
    "    eye_data = experiment.devices[\"eye_tracker\"]._data\n",
    "    experiment.devices[\"eye_tracker\"].normalize_init()\n",
    "    eye_data = experiment.devices[\"eye_tracker\"].normalize_data(eye_data)\n",
    "    eye_fs = get_fs(experiment, \"eye_tracker\")\n",
    "    eye_time = experiment.devices[\"eye_tracker\"].start_time + np.arange(len(eye_data)) / eye_fs\n",
    "\n",
    "    # as we give beh together - filter out any times where at least one variable is a nan\n",
    "    nan_mask = np.isnan(experiment.devices[\"eye_tracker\"]._data).any(axis=1)\n",
    "    eye_time = eye_time[~nan_mask]\n",
    "    eye_data = eye_data[~nan_mask]\n",
    "\n",
    "    assert len(eye_data) == len(eye_time)\n",
    "    if len(eye_data) == 0:\n",
    "        return None\n",
    "    \n",
    "    # '0': radius\n",
    "    # '1': radius_derivative\n",
    "    # '2': x\n",
    "    # '3': y\n",
    "    pupil = IrregularTimeSeries(\n",
    "        timestamps=eye_time,\n",
    "        location=eye_data[:, 2:].astype(np.float32),\n",
    "        size=eye_data[:, :2].astype(np.float32),\n",
    "        domain=\"auto\",\n",
    "    )\n",
    "    return pupil\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experanto_base_folder = '/mnt/vast-react/projects/neural_foundation_model/upsampling_without_hamming_30.0Hz' \n",
    "# mouse_id_folder = 'dynamic17797-4-7-Video-021a75e56847d574b9acbcc06c675055_30hz'\n",
    "# experiment = Experiment(f'{experanto_base_folder}/{mouse_id_folder}', DEFAULT_MODALITY_CONFIG, cache_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_experanto_session(\n",
    "    experanto_base_folder, mouse_id_folder,  output_dir, dataset_name=\"sensorium_data\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Converts an Experanto experiment into a Brainsets HDF5 file for POYO.\n",
    "    \"\"\"\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "    # 1. Load Experanto Data\n",
    "    # ---------------------------------------------------------\n",
    "    logging.info(f\"Loading Experanto: {experanto_base_folder}/{mouse_id_folder}\")\n",
    "\n",
    "    # [Correction 2]: Set cache_data=True.\n",
    "    # If False (default), accessing ._data on devices often returns None or incomplete data.\n",
    "    DEFAULT_MODALITY_CONFIG['responses']['sampling_rate'] = 30\n",
    "    DEFAULT_MODALITY_CONFIG['responses']['chunk_size'] = 60\n",
    "\n",
    "    DEFAULT_MODALITY_CONFIG['eye_tracker']['sampling_rate'] = 20\n",
    "    DEFAULT_MODALITY_CONFIG['eye_tracker']['chunk_size'] = 40\n",
    "\n",
    "    DEFAULT_MODALITY_CONFIG['treadmill']['sampling_rate'] = 20\n",
    "    DEFAULT_MODALITY_CONFIG['treadmill']['chunk_size'] = 40\n",
    "    DEFAULT_CONFIG['dataset']['modality_config'] = DEFAULT_MODALITY_CONFIG\n",
    "\n",
    "    experiment = Experiment(f'{experanto_base_folder}/{mouse_id_folder}', DEFAULT_MODALITY_CONFIG, cache_data=True)\n",
    "\n",
    "    # 2. Define Metadata\n",
    "    # ---------------------------------------------------------\n",
    "    brainset_desc = BrainsetDescription(\n",
    "        id=dataset_name,\n",
    "        origin_version=\"1.0.0\",\n",
    "        derived_version=\"1.0.0\",\n",
    "        source=\"local_experanto\",\n",
    "        description=\"Converted from Experanto dataset\",\n",
    "    )\n",
    "\n",
    "    subject_desc = SubjectDescription(\n",
    "        id=mouse_id_folder, # needed for poyo validation metrics to work\n",
    "        species=Species.MUS_MUSCULUS,\n",
    "        sex=Sex.UNKNOWN,  # Good practice to include if known, or handle defaults\n",
    "    )\n",
    "\n",
    "    session_desc = SessionDescription(\n",
    "        id=mouse_id_folder, # needed for poyo validation metrics to work\n",
    "        recording_date=datetime.now(),\n",
    "    )\n",
    "\n",
    "    device_desc = DeviceDescription(\n",
    "        # same as in https://github.com/neuro-galaxy/brainsets/blob/main/brainsets_pipelines/allen_visual_coding_ophys_2016/prepare_data.py#L420\n",
    "        id=mouse_id_folder.split('-')[0].split('dynamic')[-1], \n",
    "        recording_tech=RecordingTech.TWO_PHOTON_IMAGING,\n",
    "    )\n",
    "\n",
    "    # extract calcium traces\n",
    "    calcium_traces = extract_calcium_traces(experiment)\n",
    "    units = extract_units(experanto_base_folder, mouse_id_folder)\n",
    "\n",
    "    # extract stimulus and behavior data\n",
    "    stimuli_and_behavior_dict = {}\n",
    "    if \"treadmill\" in experiment.devices:\n",
    "        stimuli_and_behavior_dict[\"running\"] =  extract_running_speed(experiment)\n",
    "\n",
    "    if \"eye_tracker\" in experiment.devices:\n",
    "        pupil = extract_pupil_info(experiment)\n",
    "        if pupil is not None:\n",
    "            stimuli_and_behavior_dict[\"pupil\"] = pupil\n",
    "    \n",
    "    data = Data(\n",
    "        brainset=brainset_desc,\n",
    "        subject=subject_desc,\n",
    "        session=session_desc,\n",
    "        device=device_desc,\n",
    "        # neural activity\n",
    "        calcium_traces=calcium_traces,\n",
    "        units=units,\n",
    "        # stimuli and behavior\n",
    "        **stimuli_and_behavior_dict,\n",
    "        # domain\n",
    "        domain=calcium_traces.domain,\n",
    "    )\n",
    "    logging.info(\"Creating Splits...\")\n",
    "\n",
    "    with open(f\"{experanto_base_folder}/{mouse_id_folder}/screen/combined_meta.json\", \"r\") as file:\n",
    "        data_json = json.load(file)\n",
    "\n",
    "    all_tiers = list(set([k['tier'] for k in data_json.values() if 'tier' in k]))\n",
    "\n",
    "    train_intervals = get_intervals_for_tier(experanto_base_folder, mouse_id_folder, calcium_traces, 'train', DEFAULT_CONFIG)\n",
    "    data.set_train_domain(train_intervals)\n",
    "    # -------\n",
    "    valid_intervals = get_intervals_for_tier(experanto_base_folder, mouse_id_folder, calcium_traces, 'validation', DEFAULT_CONFIG)\n",
    "    data.set_valid_domain(valid_intervals)\n",
    "    # -------\n",
    "    if 'final_test_main' in all_tiers or 'final_test_1' in all_tiers or \"final_test\" in all_tiers:\n",
    "        if 'final_test_main' in all_tiers:\n",
    "            tier = 'final_test_main'\n",
    "        elif 'final_test_1' in all_tiers:\n",
    "            tier = 'final_test_1'\n",
    "        else:\n",
    "            tier = 'final_test'\n",
    "        test_intervals = get_intervals_for_tier(experanto_base_folder, mouse_id_folder, calcium_traces, tier, DEFAULT_CONFIG)\n",
    "        data.set_test_domain(test_intervals)\n",
    "\n",
    "    # save data to disk\n",
    "    path = os.path.join(output_dir, f\"{mouse_id_folder}.h5\")\n",
    "    with h5py.File(path, \"w\") as file:\n",
    "        data.to_hdf5(file, serialize_fn_map=serialize_fn_map)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = '/mnt/vast-react/projects/neural_foundation_model/torch_brain_polly_export/'\n",
    "experanto_base_folder = '/mnt/vast-react/projects/neural_foundation_model/upsampling_without_hamming_30.0Hz' \n",
    "# mouse_id_folder = 'dynamic17797-4-7-Video-021a75e56847d574b9acbcc06c675055_30hz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_mice = ['upsampling_without_hamming_30.0Hz/dynamic29234-6-9-Video-021a75e56847d574b9acbcc06c675055_30hz',\n",
    "'upsampling_without_hamming_30.0Hz/dynamic29514-2-9-Video-021a75e56847d574b9acbcc06c675055_30hz',\n",
    "'upsampling_without_hamming_30.0Hz/dynamic29513-3-5-Video-021a75e56847d574b9acbcc06c675055_30hz',\n",
    "'upsampling_without_hamming_30.0Hz/dynamic29156-11-10-Video-021a75e56847d574b9acbcc06c675055_30hz',\n",
    "'upsampling_without_hamming_30.0Hz/dynamic17797-8-5-Video-021a75e56847d574b9acbcc06c675055_30hz',\n",
    "'upsampling_without_hamming_30.0Hz/dynamic29228-2-10-Video-021a75e56847d574b9acbcc06c675055_30hz',\n",
    "'test_upsampling_without_hamming_30.0Hz/dynamic26872-17-20-Video-021a75e56847d574b9acbcc06c675055_30hz', \n",
    "'test_upsampling_without_hamming_30.0Hz/dynamic27204-5-13-Video-021a75e56847d574b9acbcc06c675055_30hz']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = '/mnt/vast-react/projects/neural_foundation_model/torch_brain_polly_export/normalized/'\n",
    "for t in target_mice:\n",
    "    print(f'started with {t}')\n",
    "    experanto_base_folder = f'/mnt/vast-react/projects/neural_foundation_model/{t.split(\"/\")[0]}'\n",
    "    mouse_id_folder = t.split('/')[1]\n",
    "    prepare_experanto_session(\n",
    "        experanto_base_folder, mouse_id_folder,  output_dir, dataset_name=\"normalized\" # dataset name should match the folder name!\n",
    "    )\n",
    "    print('\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "poyo_try_py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
