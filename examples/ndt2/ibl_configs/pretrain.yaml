defaults:
  - _default
  - dataset: small_10
  - model: encoder_small
  - _self_

wandb:
  run_name: pretrain

num_workers: 8
batch_size: 256

is_ssl: true
model:
  _target_: torch_brain.models.NDT2
  mask_ratio: 0.5


optimizer:
  lr: 0.0005 # Into sweep
  weight_decay: 0.01 # Into sweep
  scheduler: true
  start_factor: 0.1
  warmup_steps: 100
  decay_steps: 2500
  lr_min: 1e-6



