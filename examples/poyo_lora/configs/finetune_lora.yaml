defaults:
  - defaults.yaml
  - model: poyo_11.8M.yaml
  - dataset: perich_miller_population_2018.yaml
  - _self_

train_transforms:
  - _target_: torch_brain.transforms.UnitDropout
    max_units: 300
    min_units: 30
    mode_units: 100
    peak: 4

wandb:
  run_name: poyo_lora_finetune

epochs: 100
ckpt_path: null  # Must specify path to pretrained model checkpoint

# LoRA configuration for finetuning
lora:
  rank: 16
  alpha: 16.0
  dropout: 0.0
  init_scale: 0.01
  target_modules:
    - "to_q"
    - "to_kv"
    - "to_qkv"
    - "to_out"
  target_projections:
    - "q"
    - "k"
    - "v"
    - "out"
